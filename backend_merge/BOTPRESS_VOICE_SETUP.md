# Complete Voice Recognition Setup - Summary

## üéØ Answer to Your Question

### **Yes, Botpress requires ONE small change:**

Add this parameter to your voice API call:
```json
"output_format": "both"
```

That's it! The backend is already fully updated and working.

---

## üìä What Changed in Backend vs What You Need to Do in Botpress

### Backend Changes (Already Done ‚úÖ):
1. **NLU Fixed** - Now properly constructs `/register COMMUNITY | Name | Age | Skill` format
2. **Enhanced Logging** - Added `[VOICE]` prefixed logs for debugging
3. **Skill Detection** - Automatically detects 15+ skills from natural speech
4. **Better Pattern Matching** - More flexible regex for natural language understanding

### Botpress Changes (You Need to Do üîß):
1. **Add `output_format` parameter** to voice API request (REQUIRED)
2. **Update `apiBaseUrl`** if you restarted ngrok (ROUTINE)

---

## üé¨ Complete Step-by-Step Botpress Implementation

### Phase 1: Initial Setup (One-Time)

#### Step 1: Configure Base URL
1. Open Botpress Studio
2. Click **"Variables"** (bottom left, gear icon)
3. Click **"+ Add Variable"**
4. Configure:
   - **Name:** `apiBaseUrl`
   - **Type:** Configuration
   - **Scope:** Bot
   - **Value:** `https://your-ngrok-url.ngrok-free.app`
5. Click **"Save"**

#### Step 2: Create Voice Workflow
1. Go to **"Workflows"** tab
2. Click **"+ Create Workflow"**
3. **Name:** `Voice Message Handler`
4. Click **"Create"**

#### Step 3: Set Trigger
1. Click on **"Start Node"**
2. **Trigger Type:** User Sends Audio
   - *Alternative:* User Sends Message + Condition: Message Type = Audio
3. Save

---

### Phase 2: Build the Workflow

#### Step 4: Add API Call
1. Click **"+"** below Start node
2. Search **"Call API"** or **"HTTP Request"**
3. Configure:

**Basic Settings:**
- **Method:** `POST`
- **URL:** `{{config.apiBaseUrl}}/api/voice/process`

**Headers:**
```json
{
  "Content-Type": "application/json"
}
```

**Request Body:** ‚ö†Ô∏è **CRITICAL - THIS IS THE CHANGE**
```json
{
  "audio_url": "{{event.payload.audioUrl}}",
  "phone": "{{event.payload.from}}",
  "output_format": "both"
}
```

**Response Settings:**
- **Save Response To:** `voiceResponse`
- **Timeout:** 60 seconds (voice processing can take 10-30 seconds)

#### Step 5: Add Success Check
1. Add **"Conditional"** card
2. **Condition:**
```javascript
{{voiceResponse.data.success}} === true
```

#### Step 6: Handle Success (True Branch)

**Option A: Show Text Then Audio (Recommended)**

1. Add **"Send Message"** card
   - **Type:** Text
   - **Content:**
   ```
   {{voiceResponse.data.response_text}}
   ```

2. Add **"Send Audio"** card
   - **Audio URL:**
   ```
   {{voiceResponse.data.audio_url}}
   ```

**Option B: Show Transcription + Text + Audio (Detailed)**

1. Add **"Send Message"** card
   - **Content:**
   ```
   I heard: "{{voiceResponse.data.transcription}}"
   ```

2. Add **"Send Message"** card
   - **Content:**
   ```
   {{voiceResponse.data.response_text}}
   ```

3. Add **"Send Audio"** card
   - **Audio URL:**
   ```
   {{voiceResponse.data.audio_url}}
   ```

**Option C: Audio Only (Minimal)**

1. Add **"Send Audio"** card only
   - **Audio URL:**
   ```
   {{voiceResponse.data.audio_url}}
   ```

#### Step 7: Handle Failure (False Branch)
1. Add **"Send Message"** card
   - **Content:**
   ```
   Sorry, I couldn't process your voice message. Please try again or send a text message.
   ```

#### Step 8: End Both Branches
Make sure both success and failure branches end properly.

---

### Phase 3: Testing

#### Step 9: Publish Bot
1. Click **"Publish"** (top right corner)
2. Wait for deployment (status shows "Published")

#### Step 10: Test with Real Voice
1. Open WhatsApp
2. Send voice message: **"Check my balance"**
3. Observe bot response

#### Step 11: Monitor Logs

**In Botpress Studio:**
- Open **"Logs"** panel (bottom right)
- Watch for API call and response

**In Flask Terminal:**
Look for:
```
[VOICE] Received JSON request: {'audio_url': '...', 'phone': '...', 'output_format': 'both'}
[VOICE] Parameters - Phone: +237..., Output Format: both
[VOICE] Transcribing audio with Whisper...
[VOICE] Transcription: check my balance
[VOICE] Executing command: /balance
[VOICE] Command response: User not found. /register first.
[VOICE] Generating audio response with gTTS...
[VOICE] ‚úÖ Audio response URL generated: https://...
```

---

## üîç Understanding the Flow

### User Perspective:
1. üé§ User sends voice message: "Check my balance"
2. ‚è≥ Bot processes (10-30 seconds)
3. üìù Bot shows text response
4. üîä Bot plays audio response

### Technical Flow:

```
User (WhatsApp)
     ‚îÇ üé§ Voice Message
     ‚ñº
Botpress
     ‚îÇ Trigger: Audio Received
     ‚ñº
API Call: POST /api/voice/process
{
  "audio_url": "https://...",
  "phone": "+237...",
  "output_format": "both"  ‚Üê IMPORTANT!
}
     ‚îÇ
     ‚ñº
Flask Backend
     ‚îÇ 1. Download audio file
     ‚îÇ 2. Transcribe with Whisper
     ‚îÇ 3. Process with NLU ‚Üí Command
     ‚îÇ 4. Execute command ‚Üí Response
     ‚îÇ 5. Generate audio with gTTS
     ‚ñº
Response: {
  "success": true,
  "transcription": "check my balance",
  "response_text": "User not found...",
  "audio_url": "https://...response.mp3"
}
     ‚îÇ
     ‚ñº
Botpress
     ‚îÇ Send text + audio to user
     ‚ñº
User (WhatsApp)
     üìù Text: "User not found. /register first."
     üîä Audio: [plays voice saying same]
```

---

## üìã Botpress Code Reference

### Complete API Call Configuration

**Card Type:** HTTP Request / Call API

**Configuration:**
```yaml
Method: POST
URL: {{config.apiBaseUrl}}/api/voice/process
Timeout: 60000

Headers:
  Content-Type: application/json

Body:
  {
    "audio_url": "{{event.payload.audioUrl}}",
    "phone": "{{event.payload.from}}",
    "output_format": "both"
  }

Save Response To: voiceResponse
```

### Response Structure

What `voiceResponse` contains:
```json
{
  "data": {
    "success": true,
    "transcription": "check my balance",
    "response_text": "User not found. /register first.",
    "audio_url": "https://abc.ngrok-free.app/static/audio/output/response_xyz.mp3"
  },
  "status": 200
}
```

### Accessing Response Data

```javascript
// Check success
{{voiceResponse.data.success}}

// Get transcription
{{voiceResponse.data.transcription}}

// Get text response
{{voiceResponse.data.response_text}}

// Get audio URL
{{voiceResponse.data.audio_url}}
```

---

## üéØ Voice Commands Users Can Say

### Registration Commands:

**Full Registration:**
> "Register me, my name is John from Bameka, I'm 25, I do farming"

Converts to: `/register BAMEKA | John | 25 | Farming`

**Simple Registration:**
> "Register me, my name is Alice"

Converts to: `/register BAMEKA | Alice | 25 | General`

**With Different Community:**
> "Register me, I am David from Batoufam, age 30, I'm a carpenter"

Converts to: `/register BATOUFAM | David | 30 | Carpenter`

### Other Commands:

**Balance:**
> "Check my balance"
> "How much money do I have"

**Transfer:**
> "Transfer 100 to plus two three seven six zero zero..."

**Search:**
> "Find a plumber"
> "Search for farming services"

**Help:**
> "Help"
> "What can you do"

---

## üö® Troubleshooting

### Problem 1: No `audio_url` in Response

**Symptom:** Response has `response_text` but no `audio_url`

**Cause:** `output_format` not set to "both"

**Fix:** Check your Botpress API call body includes:
```json
"output_format": "both"
```

**Verify in Flask logs:**
```
[VOICE] Parameters - Phone: +237..., Output Format: both  ‚Üê Should say "both"
```

If you see:
```
[VOICE] ‚ö†Ô∏è Skipping audio generation - output_format is 'text'
```
Then Botpress is sending wrong format.

---

### Problem 2: Audio Doesn't Play

**Symptom:** `audio_url` exists but WhatsApp doesn't play it

**Possible Causes:**
1. Ngrok URL expired
2. Audio file not accessible
3. WhatsApp doesn't support the format

**Fix:**
1. Test audio URL in browser (should download MP3)
2. Check ngrok is running: `curl https://your-ngrok-url.ngrok-free.app`
3. Restart ngrok if needed, update `apiBaseUrl`

---

### Problem 3: Wrong Transcription

**Symptom:** Bot heard wrong words

**Cause:** Whisper misheard the audio

**Fixes:**
- Speak more clearly and slowly
- Reduce background noise
- Use simple English words
- Show transcription to user so they can retry

**Example:**
Add this card to show what was heard:
```
I heard: "{{voiceResponse.data.transcription}}"

Did I understand correctly?
```

---

### Problem 4: Command Not Recognized

**Symptom:** Transcription is correct but command fails

**Example:**
```
Transcription: "check balance"
Response: "I didn't quite understand that..."
```

**Cause:** NLU couldn't match the pattern

**Fix:** Use more standard phrasing:
- ‚úÖ "Check my balance"
- ‚ùå "check balance" (missing "my")

See `VOICE_COMMAND_GUIDE.md` for full list of supported commands.

---

### Problem 5: Slow Response (30+ seconds)

**Symptom:** Takes too long to respond

**Causes:**
1. Whisper model loading (first time)
2. Long audio file
3. Slow internet

**Fixes:**
1. First voice message is always slower (model loading)
2. Keep voice messages under 10 seconds
3. Increase Botpress API timeout to 60 seconds
4. Show "Processing..." message while waiting

**Add Loading Message:**
Before API call, add:
```
Send Message: "Processing your voice message, please wait..."
```

---

## ‚úÖ Final Checklist

### Backend (Already Done):
- [x] NLU fixed to construct proper commands
- [x] Enhanced logging with `[VOICE]` prefix
- [x] Skill detection from natural speech
- [x] Default values for missing fields
- [x] Flask server restarted

### Botpress (You Need to Do):
- [ ] Create `apiBaseUrl` configuration variable
- [ ] Create "Voice Message Handler" workflow
- [ ] Set trigger to "User Sends Audio"
- [ ] Add HTTP Request card
- [ ] Configure URL: `{{config.apiBaseUrl}}/api/voice/process`
- [ ] Set request body with `"output_format": "both"`
- [ ] Add response handlers (text + audio)
- [ ] Add error handling
- [ ] Publish bot
- [ ] Test with voice message

### Verification:
- [ ] Send voice: "Check my balance"
- [ ] Bot responds with audio
- [ ] Flask logs show `[VOICE]` entries
- [ ] Flask logs show: `Output Format: both`
- [ ] Flask logs show: `‚úÖ Audio response URL generated`

---

## üìö Documentation Files

I've created these guides for you:

1. **BOTPRESS_VOICE_SETUP.md** - Complete step-by-step setup guide (THIS FILE)
2. **BOTPRESS_QUICK_REF.md** - Quick reference with exact code snippets
3. **VOICE_COMMAND_GUIDE.md** - Supported voice commands and NLU improvements
4. **DEBUG_VOICE_ISSUE.md** - Debugging guide for voice issues
5. **VOICE_FIX_SUMMARY.md** - Summary of voice response fixes
6. **botpress_guide.md** - Updated with `output_format` parameter

---

## üéâ You're All Set!

**Summary:**
- ‚úÖ Backend is fixed and ready
- üîß Botpress just needs `"output_format": "both"` added
- üìñ Follow the step-by-step guide above
- üé§ Test with "Check my balance"
- üìä Monitor Flask logs to verify

**The only change needed in Botpress is adding one line:**
```json
"output_format": "both"
```

Everything else in the backend is already working! üöÄ
